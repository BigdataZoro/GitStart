利用大内存为计算服务
堆外内存谁申请谁管理
每个map task是一个进程，而每个spark task是一个线程（spark works 为一个进程，包含多个线程）
spark 的计算和资源调度耦合性很高

Hadoop MapReduce缺点：

表达能力有限
磁盘IO开销大，任务之间的衔接涉及IO开销
延迟高，Map任务要全部结束，reduce任务才能开始。
Spark借鉴Hadoop MapReduce优点的同时，解决了MapReuce所面临的问题，有如下优点：
Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供多种数据集操作类型，编程模型比Hadoop MapReduce更灵活。
Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高
Spark基于DAG的任务调度执行机制，要优于Hadoop MapReduce的迭代执行机制。

一旦经过suffer,就要转换stage(划分一个suffer);action算子启动执行job
RDD有5个属性，3个共有，2个可选

RDD（计算功能的封装）的数据只有在调用collect方法时,才真正执行业务逻辑操作

makeRDD方法在底层实现时，其实就是调用了rdd对象的paralelize方法

textFiles 方法以行为单位来读取数据，wholeTextFiles 方法以文件为单位读取数据

当使用方法创建RDD时，未指定分区数（与并行度相关），会在默认的情况下，从配置文件对象获取相关配置参数，如获取不到，默认并行度将使用totalCores属性值（指的是当前运行环境的最大可能核数）

从文件中获取数据时，为指定分区数，由于默认的并行度大于2，取默认并行度与2之间的最小值；因此此时的默认最小分区数为2（此值只保证最小分区数），之后实际分区以Hadoop的分区划分方式进行分区。

spark读取文件时，采用的是hadoop的方式，一行一行读取与字节数无关；读取数据时以偏移量为单位，且偏移量不会被重复读取

rdd的计算一个分区内的数据是一个个的执行逻辑，只有前面一个数据全部的逻辑执行完后才会执行下一个数据，即分区内数据执行是有序的；不同的分区数据计算是无序的


SQL---2.0
SQL---3.0
SQL---4.0






























